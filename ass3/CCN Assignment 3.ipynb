{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.functions.evaluation import accuracy\n",
    "from chainer.functions.loss import softmax_cross_entropy\n",
    "from chainer import link\n",
    "from chainer import reporter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global HIDDEN_UNITS\n",
    "HIDDEN_UNITS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create toy data - compute sum of the previous and current input\n",
    "def create_data(n=3000):\n",
    "\n",
    "    X = np.random.rand(n,1).astype('float32')\n",
    "    T = np.sum(np.hstack((X[0:-1],X[1:])),axis=1)\n",
    "    T = np.hstack([0, T[0:]]).astype('float32')\n",
    "    T = T.reshape([n,1])\n",
    "\n",
    "    return TupleDataset(X, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN(Chain):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.LSTM(None, HIDDEN_UNITS)\n",
    "            self.out = L.Linear(HIDDEN_UNITS, 1)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = self.l1(x)\n",
    "        y = self.out(h1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Regressor(link.Chain):\n",
    "\n",
    "    compute_accuracy = False\n",
    "\n",
    "    def __init__(self, predictor,\n",
    "                 lossfun=softmax_cross_entropy.softmax_cross_entropy,\n",
    "                 accfun=accuracy.accuracy,\n",
    "                 label_key=-1):\n",
    "        if not (isinstance(label_key, (int, str))):\n",
    "            raise TypeError('label_key must be int or str, but is %s' %\n",
    "                            type(label_key))\n",
    "\n",
    "        super(Regressor, self).__init__()\n",
    "        self.lossfun = lossfun\n",
    "        self.accfun = accfun\n",
    "        self.y = None\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        self.label_key = label_key\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.predictor = predictor\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "\n",
    "        if isinstance(self.label_key, int):\n",
    "            if not (-len(args) <= self.label_key < len(args)):\n",
    "                msg = 'Label key %d is out of bounds' % self.label_key\n",
    "                raise ValueError(msg)\n",
    "            t = args[self.label_key]\n",
    "            if self.label_key == -1:\n",
    "                args = args[:-1]\n",
    "            else:\n",
    "                args = args[:self.label_key] + args[self.label_key + 1:]\n",
    "        elif isinstance(self.label_key, str):\n",
    "            if self.label_key not in kwargs:\n",
    "                msg = 'Label key \"%s\" is not found' % self.label_key\n",
    "                raise ValueError(msg)\n",
    "            t = kwargs[self.label_key]\n",
    "            del kwargs[self.label_key]\n",
    "\n",
    "        self.y = None\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        self.y = self.predictor(*args, **kwargs)\n",
    "        self.loss = self.lossfun(self.y, t)\n",
    "        reporter.report({'loss': self.loss}, self)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Iterator(data):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = data\n",
    "        self.done = False\n",
    "        \n",
    "    def next(self):\n",
    "        # go on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(train_iter, val_iter, test_data, network, regressor, optimizer, max_epoch):\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    \n",
    "    mini_batch_losses = []\n",
    "\n",
    "    while train_iter.epoch < max_epoch:\n",
    "        # Get next mini-batch\n",
    "        batch = train_iter.next()\n",
    "        image_train, target_train = concat_examples(batch)\n",
    "\n",
    "        # Prediction\n",
    "        prediction_train = network(image_train)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = regressor(prediction_train, target_train)\n",
    "        mini_batch_losses.append(loss.data)\n",
    "\n",
    "        # Compute gradients\n",
    "        network.cleargrads()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update variables\n",
    "        optimizer.update()\n",
    "\n",
    "        # Check the validation accuracy of prediction after every epoch\n",
    "        if train_iter.is_new_epoch:  # If this iteration is the final iteration of the current epoch\n",
    "\n",
    "            # Save the training loss\n",
    "            training_losses.append(np.mean(mini_batch_losses))\n",
    "            mini_batch_losses = []\n",
    "\n",
    "            val_losses = []\n",
    "            val_accuracies = []\n",
    "            while True:\n",
    "                val_batch = val_iter.next()\n",
    "                image_val, target_val = concat_examples(val_batch)\n",
    "\n",
    "                # Forward the validation data\n",
    "                prediction_val = network(image_val)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss_val = regressor(prediction_val, target_val)\n",
    "                val_losses.append(loss_val.data)\n",
    "\n",
    "                if val_iter.is_new_epoch:\n",
    "                    val_iter.epoch = 0\n",
    "                    val_iter.current_position = 0\n",
    "                    val_iter.is_new_epoch = False\n",
    "                    val_iter._pushed_position = None\n",
    "\n",
    "                    validation_losses.append(np.mean(val_losses))\n",
    "                    break\n",
    "\n",
    "    # Predict full test set\n",
    "    image_test, target_test = concat_examples(test_data)\n",
    "    # Forward test data\n",
    "    prediction_test = network(image_test)\n",
    "    # Calculate loss and accuracy\n",
    "    loss_test = regressor(prediction_test, target_test)\n",
    "\n",
    "    print('test_loss: ' + str(loss_test.data))\n",
    "    return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The batch size of x must be equal to or less thanthe size of the previous state h.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-6489a43de545>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-66-6489a43de545>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-294ae490b77b>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(train_iter, val_iter, test_data, network, regressor, optimizer, max_epoch)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mimage_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# Forward test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mprediction_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Calculate loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mloss_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b4fea1c3f7eb>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/emiel/anaconda2/lib/python2.7/site-packages/chainer/links/connection/lstm.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    279\u001b[0m                 msg = ('The batch size of x must be equal to or less than'\n\u001b[0;32m    280\u001b[0m                        'the size of the previous state h.')\n\u001b[1;32m--> 281\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mh_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                 h_update, h_rest = split_axis.split_axis(\n",
      "\u001b[1;31mTypeError\u001b[0m: The batch size of x must be equal to or less thanthe size of the previous state h."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Create data\n",
    "    train = create_data()\n",
    "    test = create_data()\n",
    "    \n",
    "    # TODO define an own iterator which loops over the whole training set during the epoch\n",
    "    \n",
    "    # Initialize iterators\n",
    "    train_iter = iterators.SerialIterator(train, batch_size=1, shuffle=False, repeat=False)\n",
    "    val_iter = iterators.SerialIterator(test, batch_size=1, repeat=False, shuffle=False)\n",
    "\n",
    "    # Define model\n",
    "    network = RNN()\n",
    "    regressor = Regressor(network, F.mean_squared_error)\n",
    "    optimizer = optimizers.SGD()\n",
    "    optimizer.setup(network)\n",
    "    \n",
    "    training_losses, validation_losses = run(train_iter, val_iter, test, network, regressor, optimizer, 1)\n",
    "    \n",
    "    plt.plot(training_losses, label='Training loss')\n",
    "    plt.plot(validation_losses, label='Validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
