{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCN Assignment 6: Generative\tAdversarial\tNetworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.datasets import TupleDataset\n",
    "from chainer.functions.evaluation import accuracy\n",
    "from chainer.functions.loss import softmax_cross_entropy\n",
    "from chainer import link\n",
    "from chainer import reporter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make loss function such that loss is high when discriminator \n",
    "# classifies generator network output as fake 0, and\n",
    "# low when generator network output as being a real 0\n",
    "\n",
    "class Generator(Chain):\n",
    "    def __init__(self, n_units, n_output):\n",
    "        super(Generator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(n_units, n_units) # fully connected layer\n",
    "            self.batch_norm = L.BatchNormalization(n_units) # batch normalization\n",
    "            self.deconv = L.Deconvolution2D(None, n_output) # deconvolution layer\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = self.batch_norm(h1)\n",
    "        h3 = self.deconv(h2)\n",
    "        y = F.sigmoid(h3)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "    def __init__(self, n_out):\n",
    "        super(Discriminator, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv = L.Convolution2D(None, out_channels=5, ksize=5, stride=1, pad=0)\n",
    "            self.fc1 = L.Linear(None, n_out)\n",
    "            \n",
    "        def __call__(self, x):\n",
    "            h1 = self.conv1(x)\n",
    "            h2 = F.max_pooling_2d(h1, ksize=5, stride=1, pad=0) # max pooling layer\n",
    "            y = F.relu(self.fc1(h2))\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regressor(link.Chain):\n",
    "\n",
    "    compute_accuracy = False\n",
    "\n",
    "    def __init__(self, predictor,\n",
    "                 lossfun=softmax_cross_entropy.softmax_cross_entropy,\n",
    "                 accfun=accuracy.accuracy,\n",
    "                 label_key=-1):\n",
    "        if not (isinstance(label_key, (int, str))):\n",
    "            raise TypeError('label_key must be int or str, but is %s' %\n",
    "                            type(label_key))\n",
    "\n",
    "        super(Regressor, self).__init__()\n",
    "        self.lossfun = lossfun\n",
    "        self.accfun = accfun\n",
    "        self.y = None\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        self.label_key = label_key\n",
    "\n",
    "        with self.init_scope():\n",
    "            self.predictor = predictor\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "\n",
    "        if isinstance(self.label_key, int):\n",
    "            if not (-len(args) <= self.label_key < len(args)):\n",
    "                msg = 'Label key %d is out of bounds' % self.label_key\n",
    "                raise ValueError(msg)\n",
    "            t = args[self.label_key]\n",
    "            if self.label_key == -1:\n",
    "                args = args[:-1]\n",
    "            else:\n",
    "                args = args[:self.label_key] + args[self.label_key + 1:]\n",
    "        elif isinstance(self.label_key, str):\n",
    "            if self.label_key not in kwargs:\n",
    "                msg = 'Label key \"%s\" is not found' % self.label_key\n",
    "                raise ValueError(msg)\n",
    "            t = kwargs[self.label_key]\n",
    "            del kwargs[self.label_key]\n",
    "\n",
    "        self.y = None\n",
    "        self.loss = None\n",
    "        self.accuracy = None\n",
    "        self.y = self.predictor(*args, **kwargs)\n",
    "        self.loss = self.lossfun(self.y, t)\n",
    "        reporter.report({'loss': self.loss}, self)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(generator, discriminator, regressor, classifier, gen_optimizer, discr_optimizer, true_train_iter, true_val_iter, noise_train_iter):\n",
    "#     First generate a sample with the generator network.\n",
    "#     Classify it with the discriminator network, \n",
    "#     calculate the loss such that you enhance samples that the discriminator thinks are real \n",
    "#     and update the networks. \n",
    "#     Next calculate the loss of the generated sample enhancing those samples \n",
    "#     that the discriminator correctly recognizes as fake. \n",
    "#     Combine this with the loss that the discriminator gets on real images \n",
    "#     and update the networks based on this combined loss.\n",
    "    \n",
    "    # get next mini-batch from generator\n",
    "    noise_batch = noise_train_iter.next()\n",
    "    # generate batch\n",
    "    gen = generator(noise_batch)\n",
    "    # classify\n",
    "    clas = discriminator(gen)\n",
    "    # compute loss\n",
    "    label = np.array([0])\n",
    "    discr_loss = classifier(clas, label)\n",
    "    # compute gradients\n",
    "    classifier.cleargrads()\n",
    "    discr_loss.backward()\n",
    "    # update variables\n",
    "    discr_optimizer.update()\n",
    "    \n",
    "    # loss of generated sample\n",
    "    gen_loss = 1-discr_loss\n",
    "    # compute gradients\n",
    "    regressor.cleargrads()\n",
    "    gen_loss.backward()\n",
    "    # update variables\n",
    "    gen_optimizer.update()\n",
    "    \n",
    "    # get next mini-batch from real data\n",
    "    real_batch = true_train_iter.next()\n",
    "    # classify\n",
    "    clas = discriminator(gen)\n",
    "    # compute loss\n",
    "    label = np.array([1])\n",
    "    discr_loss = classifier(clas, label)\n",
    "    # compute gradients\n",
    "    classifier.cleargrads()\n",
    "    discr_loss.backward()\n",
    "    # update variables\n",
    "    discr_optimizer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "numpy.ndarray or cuda.ndarray are expected.\nActual: <type 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-42ec0ca5a8fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-42ec0ca5a8fc>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mdiscr_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscr_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_train_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_val_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_train_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-24e6baac7086>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(generator, discriminator, regressor, classifier, gen_optimizer, discr_optimizer, true_train_iter, true_val_iter, noise_train_iter)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnoise_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_train_iter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# generate batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;31m# classify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mclas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3096bdcdc910>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mh3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/emiel/anaconda2/lib/python2.7/site-packages/chainer/links/connection/linear.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/emiel/anaconda2/lib/python2.7/site-packages/chainer/functions/connection/linear.pyc\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(x, W, b)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mLinearFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/emiel/anaconda2/lib/python2.7/site-packages/chainer/function.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    178\u001b[0m         inputs = [x if isinstance(x, variable.Variable)\n\u001b[0;32m    179\u001b[0m                   \u001b[1;32melse\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                   for x in inputs]\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0min_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/emiel/anaconda2/lib/python2.7/site-packages/chainer/variable.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m             msg = '''numpy.ndarray or cuda.ndarray are expected.\n\u001b[0;32m    326\u001b[0m Actual: {0}'''.format(type(data))\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# Use a list as a data structure to hold the data array indirectly to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: numpy.ndarray or cuda.ndarray are expected.\nActual: <type 'list'>"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # generate the real data\n",
    "    train_data, test_data = get_mnist(n_train=1000, n_test=100, with_label=False, classes = [0])\n",
    "    \n",
    "    # generate the fake data\n",
    "    noise_train = np.random.rand(1000,28,28)\n",
    "    fake_test = np.random.rand(100,28,28)\n",
    "    \n",
    "    # initialize interators\n",
    "    true_train_iter = iterators.SerialIterator(train_data, batch_size=64, shuffle=True)\n",
    "    true_val_iter = iterators.SerialIterator(test_data, batch_size=100, repeat=False, shuffle=False)\n",
    "    noise_train_iter = iterators.SerialIterator(noise_train, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # define generator\n",
    "    generator = Generator(784, 784)\n",
    "    regressor = Regressor(generator, F.mean_squared_error)\n",
    "    gen_optimizer = optimizers.SGD()\n",
    "    gen_optimizer.setup(regressor)\n",
    "    \n",
    "    # define discriminator\n",
    "    discriminator = Discriminator(1)\n",
    "    classifier = L.Classifier(discriminator, F.sigmoid_cross_entropy)\n",
    "    discr_optimizer = optimizers.SGD()\n",
    "    discr_optimizer.setup(classifier)\n",
    "    \n",
    "    run(generator, discriminator, regressor, classifier, gen_optimizer, discr_optimizer, true_train_iter, true_val_iter, noise_train_iter)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
